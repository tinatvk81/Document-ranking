{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFciBLgE07dX",
        "outputId": "1130c724-6347-4aa5-bd0a-e1657e318571"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas scikit-learn nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4qBaGxqRYsK",
        "outputId": "dcb80679-f8a9-4784-ef7d-77b6422e0dad"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/FUM_IR_1402-02_HW#1_Resources.zip'\n",
        "dataset_path='/content/FUM_IR_1402-02_HW#1_Resources'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MlcSNCufPmta"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def load_dataset(path):\n",
        "  docs_path = os.path.join(path, 'cranfieldDocs')\n",
        "  query_path = os.path.join(path, 'queries.txt')\n",
        "  my_query_path = os.path.join(path, 'my-query.txt')\n",
        "  file_list = os.listdir(docs_path)\n",
        "  docs=[]\n",
        "  for file_name in file_list:\n",
        "    file_path = os.path.join(docs_path, file_name)\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        docs.append((file_name,content))\n",
        "\n",
        "    queries=[]\n",
        "    with open(query_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        # Remove newline characters from each line\n",
        "        queries = [(id+1,line.strip()) for id,line in enumerate(lines)]\n",
        "    my_queries=[]\n",
        "    with open(my_query_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        # Remove newline characters from each line\n",
        "        my_queries = [(id+1,line.strip()) for id,line in enumerate(lines)]\n",
        "    dataset={\n",
        "      'docs':docs,\n",
        "      'queries':queries,\n",
        "      'my_query':my_queries\n",
        "      }\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XoMWR11qfWkQ"
      },
      "outputs": [],
      "source": [
        "def load_relevace(folder_path):\n",
        "    id_dict = {}\n",
        "    filename = os.path.join(folder_path, 'relevance.txt')\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            id, element = line.strip().split()\n",
        "            id = int(id)\n",
        "            element = int(element)\n",
        "            if id not in id_dict:\n",
        "                id_dict[id] = []\n",
        "            id_dict[id].append(element)\n",
        "    return id_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zsqxestxyxZK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "dataset = load_dataset(dataset_path)\n",
        "relevance = load_relevace(dataset_path)\n",
        "def preprocess_document(doc):\n",
        "    doc = doc.lower()\n",
        "\n",
        "    # Remove SGML tags and only keep title and text\n",
        "    title = re.search(r'<title>(.*?)</title>', doc, re.S)\n",
        "    text = re.search(r'<text>(.*?)</text>', doc, re.S)\n",
        "    doc = \"\"\n",
        "    if title:\n",
        "        doc += title.group(1) + \" \"\n",
        "    if text:\n",
        "        doc += text.group(1)\n",
        "\n",
        "    # Remove SGML tags\n",
        "    doc = re.sub(r'<.*?>', '', doc)\n",
        "\n",
        "    # Remove punctuation marks and numbers\n",
        "    doc = re.sub(r'[^a-z\\s]', ' ', doc)\n",
        "\n",
        "    tokens = word_tokenize(doc)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    porter = PorterStemmer()\n",
        "\n",
        "    tokens = [porter.stem(token) for token in tokens if token not in stop_words]\n",
        "\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zKMnCnBcTyfD"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "doc_ids = []\n",
        "for doc_id,text in dataset['docs']:\n",
        "    preprocessed_doc = preprocess_document(text)\n",
        "    documents.append(preprocessed_doc)\n",
        "    doc_ids.append(doc_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HfdQtwIaUZGJ"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "def preprocess_query(query):\n",
        "    # Remove punctuation marks and numbers\n",
        "    doc = re.sub(r'[^a-z\\s]', ' ', query)\n",
        "\n",
        "    tokens = word_tokenize(doc)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    porter = PorterStemmer()\n",
        "\n",
        "    tokens = [porter.stem(token) for token in tokens if token not in stop_words]\n",
        "\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "def related_docs(n,queries=dataset['queries']):\n",
        "  top={}\n",
        "  # Iterate over queries and perform vector space retrieval\n",
        "  for query_id,text in queries:\n",
        "      query_text = preprocess_query(text)\n",
        "      query_vector = vectorizer.transform([query_text])\n",
        "\n",
        "      # Compute cosine similarity between the query and all documents\n",
        "      similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "      # print(f'q: {query_vector}')\n",
        "      # print(f'tf: {tfidf_matrix}')\n",
        "\n",
        "      # Get the top n most similar documents\n",
        "      top_indices = similarities.argsort()[-1*n:][::-1]\n",
        "      top_docs = [(doc_ids[idx], similarities[idx]) for idx in top_indices]\n",
        "      top[query_id]=[]\n",
        "      # Print the query ID and top n documents\n",
        "      # print(f\"Query ID: {query_id}\")\n",
        "      for doc_id, score in top_docs:\n",
        "          print(f'(query_id:{query_id},doc_id:{doc_id}, Score: {score})')\n",
        "          # print(f\"Doc ID: {doc_id}, Score: {score}\")\n",
        "          top[query_id].append(int(doc_id))\n",
        "      print(\"\\n\")\n",
        "  return top\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXkCSvtLdu2t",
        "outputId": "9b3b4860-8d8c-4df9-fbbc-941fd349c6ea"
      },
      "outputs": [],
      "source": [
        "top= related_docs(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hVhnqQaQhNO4"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(top_lists):\n",
        "    metrics={}\n",
        "    precision_sum=0\n",
        "    recall_sum=0\n",
        "    for query_id,top in top_lists.items():\n",
        "        #precision\n",
        "        tp=0\n",
        "        for i in top:\n",
        "          if i in relevance[query_id] :\n",
        "            tp+=1\n",
        "        precision = tp/len(top)\n",
        "        recall= tp/len(relevance[query_id])\n",
        "        precision_sum+=precision\n",
        "        recall_sum+=recall\n",
        "        metrics[query_id]=(precision,recall)\n",
        "    avg_pre=precision_sum/10\n",
        "    avg_recall=recall_sum/10\n",
        "    return metrics ,avg_pre ,avg_recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w4j2ao1mlde",
        "outputId": "c74f50b3-7c3a-4ef2-88a8-50f6449a53c4"
      },
      "outputs": [],
      "source": [
        "top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dSTwjRQ9hEem"
      },
      "outputs": [],
      "source": [
        "metrics ,avg_pre ,avg_recall =calculate_metrics(top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2WFj4I4pCfG",
        "outputId": "24b71923-1844-473d-9650-df657d0df1cd"
      },
      "outputs": [],
      "source": [
        "list_metrics={}\n",
        "for n in [10,20,50,100,500]:\n",
        "  print(f'n={n}')\n",
        "  top=related_docs(n)\n",
        "  metrics ,avg_pre ,avg_recall =calculate_metrics(top)\n",
        "  list_metrics[n]={\n",
        "      'precision_average':avg_pre ,\n",
        "      'recall_average':avg_recall,\n",
        "      'queries':metrics\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoYfrbJrqYfF",
        "outputId": "f7f83f81-372f-4526-a121-5c2168df7ddf"
      },
      "outputs": [],
      "source": [
        "list_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wsTLRtRwrZMb",
        "outputId": "1de31cfc-a405-4488-d576-cb7a370a2a25"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The provided list_metrics\n",
        "# list_metrics = {\n",
        "#     10: {'precision_average': 0.23000000000000004, 'recall_average': 0.20190058479532164},\n",
        "#     20: {'precision_average': 0.175, 'recall_average': 0.3157748538011696},\n",
        "#     50: {'precision_average': 0.1, 'recall_average': 0.43157894736842106},\n",
        "#     100: {'precision_average': 0.06999999999999999, 'recall_average': 0.5564766081871345},\n",
        "#     500: {'precision_average': 0.0238, 'recall_average': 0.9430555555555555}\n",
        "# }\n",
        "\n",
        "# Extracting the IDs, precision, and recall values\n",
        "ids = list(list_metrics.keys())\n",
        "precision_averages = [list_metrics[id]['precision_average'] for id in ids]\n",
        "recall_averages = [list_metrics[id]['recall_average'] for id in ids]\n",
        "\n",
        "# Plotting the list_metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(ids, precision_averages, marker='o', label='Average Precision')\n",
        "plt.plot(ids, recall_averages, marker='o', label='Average Recall')\n",
        "# Adding the IDs as x-tick labels\n",
        "plt.xticks(ids, ids)\n",
        "plt.xlabel('N')\n",
        "plt.ylabel('Average Value')\n",
        "plt.title('Average Precision and Recall')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpkhV2t-GjIt",
        "outputId": "0e108c94-8abb-4e42-d8be-9aeee52344b1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for n in [10,20,50,100,500]:\n",
        "  print(f'n={n}')\n",
        "  top=related_docs(n,queries=dataset['my_query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv0BIMyWSPkp",
        "outputId": "90d9a703-296d-43da-9789-1372838650d7"
      },
      "outputs": [],
      "source": [
        "print(f'n={3}')\n",
        "top=related_docs(3,queries=dataset['my_query'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
